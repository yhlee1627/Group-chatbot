from fastapi import APIRouter
from pydantic import BaseModel
from openai import AsyncOpenAI
from typing import List, Optional
from dotenv import load_dotenv
import os
import traceback

load_dotenv()

router = APIRouter()
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ğŸ’¬ ë©”ì‹œì§€ ëª¨ë¸
class ChatMessage(BaseModel):
    sender_id: str
    message: str

# ğŸ“¤ í‰ê°€ ìš”ì²­ ëª¨ë¸
class EvaluationRequest(BaseModel):
    topic_id: str
    rubric_prompt: str
    target_student: Optional[str] = None
    room_id: Optional[str] = None
    class_id: Optional[str] = None
    conversation_id: Optional[str] = None
    messages: List[ChatMessage]

# ğŸ“¥ í‰ê°€ ì‘ë‹µ ëª¨ë¸
class EvaluationResponse(BaseModel):
    feedback: str

# ğŸ—ƒ Supabase ì €ì¥ í•¨ìˆ˜
def save_evaluation_result(summary, topic_id, room_id, student_id=None,
                           class_id=None, conversation_id=None):
    from supabase import create_client

    url = os.getenv("SUPABASE_URL")
    key = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
    supabase = create_client(url, key)

    data = {
        "summary": summary,
        "topic_id": topic_id,
        "room_id": room_id,
        "student_id": student_id,
        "class_id": class_id,
        "conversation_id": conversation_id,
        "evaluation_type": "individual" if student_id else "group",
    }

    print("ğŸ“¥ ì €ì¥í•  í‰ê°€ ê²°ê³¼:", data)

    try:
        res = supabase.table("gpt_chat_evaluations").insert(data).execute()
        print("âœ… í‰ê°€ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:", res)
    except Exception as e:
        print("âŒ í‰ê°€ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨:", e)
        traceback.print_exc()

# ğŸ¯ GPT í‰ê°€ API ë¼ìš°í„°
@router.post("/evaluate-chat", response_model=EvaluationResponse)
async def evaluate_chat(data: EvaluationRequest):
    print("ğŸ“© í‰ê°€ ìš”ì²­ ë„ì°©:", data.topic_id)
    print("ğŸ‘¤ í‰ê°€ ëŒ€ìƒ:", data.target_student or "ì „ì²´")

    # 1. system_prompt êµ¬ì„±
    system_prompt = f"""
ë‹¹ì‹ ì€ êµì‚¬ê°€ ì‘ì„±í•œ ë£¨ë¸Œë¦­ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìƒ ëŒ€í™”ë¥¼ í‰ê°€í•˜ëŠ” AI í‰ê°€ ë³´ì¡°ìì…ë‹ˆë‹¤.

ğŸ“‹ ë£¨ë¸Œë¦­:
{data.rubric_prompt}

ì•„ë˜ì˜ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì—¬ êµì‚¬ì—ê²Œ ì œê³µí•  í‰ê°€ í”¼ë“œë°±ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

    # 2. ëŒ€í™” ë¡œê·¸ êµ¬ì„±
    chat_log = "\n".join([f"{m.sender_id}: {m.message}" for m in data.messages])

    messages = [
        {"role": "system", "content": system_prompt.strip()},
        {"role": "user", "content": f"ëŒ€í™”:\n{chat_log}"}
    ]

    try:
        # 3. GPT ì‘ë‹µ ìƒì„±
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.7,
        )
        feedback = response.choices[0].message.content.strip()
        print("ğŸ“¤ GPT í‰ê°€ ê²°ê³¼ ìƒì„± ì™„ë£Œ")
        print("ğŸ“„ í‰ê°€ ìš”ì•½:\n", feedback[:200], "...")

        # 4. í‰ê°€ ê²°ê³¼ ì €ì¥
        save_evaluation_result(
            summary=feedback,
            topic_id=data.topic_id,
            room_id=data.room_id,
            student_id=data.target_student,
            class_id=data.class_id,
            conversation_id=data.conversation_id
        )

        return EvaluationResponse(feedback=feedback)

    except Exception as e:
        print("âŒ GPT í‰ê°€ ì˜¤ë¥˜:", e)
        traceback.print_exc()
        return EvaluationResponse(feedback="GPT í‰ê°€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")