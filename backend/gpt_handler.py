import os
import json
from datetime import datetime
from openai import AsyncOpenAI
from supabase_client import (
    get_room_history,
    get_system_prompt,
    get_student_name,
    save_message_to_db
)

client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

class GPTInterventionService:
    """
    GPT ê°œì… ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    - 1ë‹¨ê³„: ê°œì… ì—¬ë¶€ íŒë‹¨
    - 2ë‹¨ê³„: ì‘ë‹µ ìƒì„± ë° ì „ì†¡
    """

    def __init__(self, room_id):
        self.room_id = room_id

    async def should_respond(self, recent_messages):
        chat_text = "\n".join([f"{m.get('name', m['sender_id'])}: {m['message']}" for m in recent_messages])
        system_prompt = await get_system_prompt(self.room_id)

        judgment_instruction = """
ì´ ì±„íŒ…ë°©ì€ ìœ„ì™€ ê°™ì€ ëª©ì ì„ ê°€ì§„ ê³µê°„ì…ë‹ˆë‹¤.

GPTëŠ” êµì‚¬ì˜ ë³´ì¡°êµì‚¬ë¡œì„œ, ë‹¤ìŒ ê¸°ì¤€ì— ë”°ë¼ ê°œì… ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ì„¸ìš”:

- íŠ¹ì • í•™ìƒì´ "ëª¨ë¥´ê² ì–´ìš”", "í•˜ê¸° ì‹«ì–´ìš”", "ì˜ ëª¨ë¥´ê² ë„¤" ë“± í˜¼ë€, ë¶€ì •, ê±°ë¶€ í‘œí˜„ì„ í•˜ë©´ ê·¸ í•™ìƒì—ê²Œ ê°œì…í•˜ì„¸ìš”.
- ëŒ€í™”ê°€ ëŠê¸°ê±°ë‚˜ ì†Œìˆ˜ë§Œ ë§í•˜ê³  ìˆê±°ë‚˜ ì£¼ì œì—ì„œ ë²—ì–´ë‚œ ê²½ìš° ì „ì²´ì—ê²Œ ê°œì…í•˜ì„¸ìš”.
- ëŒ€í™”ê°€ í™œë°œí•˜ê²Œ ì˜ ì§„í–‰ë˜ê³  ìˆë‹¤ë©´ ê°œì…í•˜ì§€ ë§ˆì„¸ìš”. ëŒ€ì‹  ê¸ì •ì ì¸ í”¼ë“œë°±ì„ ì£¼ì„¸ìš”.

ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ JSONë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{ "should_respond": false }
{ "should_respond": true, "target": "s02" }
{ "should_respond": true, "target": null }

âš ï¸ JSON ì™¸ì˜ ì„¤ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""

        full_prompt = f"{system_prompt.strip()}\n\n{judgment_instruction.strip()}"

        messages = [
            {"role": "system", "content": full_prompt},
            {"role": "user", "content": f"ìµœê·¼ ëŒ€í™”:\n{chat_text}"}
        ]

        try:
            response = await client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0
            )
            raw = response.choices[0].message.content.strip()
            print("ğŸ§  GPT íŒë‹¨ ì‘ë‹µ:", raw)
            return json.loads(raw)
        except Exception as e:
            print("âŒ íŒë‹¨ ì˜¤ë¥˜:", e)
            return {"should_respond": False}

    async def generate_feedback(self, recent_messages, intervention_type, target=None):
        system_prompt = await get_system_prompt(self.room_id)

        if intervention_type == "positive":
            system_prompt += """
í˜„ì¬ í•™ìƒë“¤ì˜ ëŒ€í™”ëŠ” ì›í™œí•˜ê²Œ ì˜ ì´ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤.
í•™ìƒë“¤ì—ê²Œ ê¸ì •ì ì¸ í”¼ë“œë°±ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì „í•´ì£¼ì„¸ìš”.
"""
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": "í•™ìƒë“¤ì˜ ëŒ€í™”ë¥¼ ê¸ì •ì ìœ¼ë¡œ í‰ê°€í•´ ì£¼ì„¸ìš”."}
            ]
            temperature = 0.5

        else:
            chat_text = "\n".join([f"{m.get('name', m['sender_id'])}: {m['message']}" for m in recent_messages])
            system_prompt += f"""
ë„ˆëŠ” {"íŠ¹ì • í•™ìƒ(" + target + ")" if target else "ì „ì²´ í•™ìƒ"}ì—ê²Œ í”¼ë“œë°±ì„ ì£¼ëŠ” êµì‚¬ì…ë‹ˆë‹¤.
í•™ìƒì˜ ìƒí™©ì— ë§ê²Œ ë”°ëœ»í•˜ê³  ëª…í™•í•˜ê²Œ ë„ì™€ì£¼ì„¸ìš”.
ê¸€ì€ 50ìë¥¼ ë„˜ì§€ ì•Šë„ë¡ ëª…ì‹¬í•˜ì„¸ìš”.
"""
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ìµœê·¼ ëŒ€í™”:\n{chat_text}"}
            ]
            temperature = 0.7

        try:
            response = await client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=temperature
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print("âŒ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜:", e)
            return "ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”."

    async def process_auto_intervention(self, recent_messages, sid_to_user, sio):
        judgment = await self.should_respond(recent_messages)
        should_respond = judgment.get("should_respond", False)
        target = judgment.get("target") if should_respond else None

        intervention_type = "intervene" if should_respond else "positive"
        gpt_text = await self.generate_feedback(recent_messages, intervention_type, target)
        gpt_time = datetime.utcnow().isoformat()

        await save_message_to_db(self.room_id, "gpt", gpt_text, "assistant", gpt_time)

        if should_respond and target:
            for sid, uid in sid_to_user.items():
                if uid == target:
                    await sio.emit("receive_message", {
                        "sender_id": "gpt",
                        "message": gpt_text,
                        "role": "assistant",
                        "timestamp": gpt_time,
                        "target": target
                    }, to=sid)
                    return
        else:
            await sio.emit("receive_message", {
                "sender_id": "gpt",
                "message": gpt_text,
                "role": "assistant",
                "timestamp": gpt_time
            }, room=self.room_id)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í‰ê°€ ì „ìš© í•¨ìˆ˜ (GPT í‰ê°€ ìƒì„±) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def evaluate_conversation(rubric_prompt: str, messages: list[dict]) -> str:
    """
    âœ… GPTì—ê²Œ ë£¨ë¸Œë¦­ê³¼ ì±„íŒ… ëŒ€í™”ë¥¼ ì „ë‹¬í•˜ì—¬ í‰ê°€ ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    - rubric_prompt: êµì‚¬ê°€ ì‘ì„±í•œ í‰ê°€ ê¸°ì¤€
    - messages: [{sender_id, message}, ...]
    - return: í‰ê°€ ìš”ì•½ í…ìŠ¤íŠ¸
    """
    try:
        system_prompt = f"""
ë‹¹ì‹ ì€ êµì‚¬ê°€ ì‘ì„±í•œ ë£¨ë¸Œë¦­ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìƒë“¤ì˜ ëŒ€í™”ë¥¼ í‰ê°€í•˜ëŠ” AI í‰ê°€ ë³´ì¡°ìì…ë‹ˆë‹¤.

ğŸ“‹ ë£¨ë¸Œë¦­:
{rubric_prompt}

ì•„ë˜ ëŒ€í™”ë¥¼ ë¶„ì„í•´ êµì‚¬ì—ê²Œ ì œê³µí•  í‰ê°€ í”¼ë“œë°±ì„ ì‘ì„±í•˜ì„¸ìš”.
"""
        chat_log = "\n".join([f"{m['sender_id']}: {m['message']}" for m in messages])

        prompt_messages = [
            {"role": "system", "content": system_prompt.strip()},
            {"role": "user", "content": f"ëŒ€í™”:\n{chat_log}"}
        ]

        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=prompt_messages,
            temperature=0.7,
        )

        return response.choices[0].message.content.strip()

    except Exception as e:
        print("âŒ GPT í‰ê°€ ìƒì„± ì˜¤ë¥˜:", e)
        return "GPT í‰ê°€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."