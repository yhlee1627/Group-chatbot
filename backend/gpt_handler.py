import os
import json
from datetime import datetime
from openai import AsyncOpenAI
from supabase_client import (
    get_room_history,
    get_system_prompt,
    get_student_name,
    save_message_to_db
)

client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

class GPTInterventionService:
    """
    GPT ê°œì… ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    - 1ë‹¨ê³„: ê°œì… ì—¬ë¶€ íŒë‹¨
    - 2ë‹¨ê³„: ì‘ë‹µ ìƒì„± ë° ì „ì†¡
    """

    def __init__(self, room_id):
        self.room_id = room_id

    async def should_respond(self, recent_messages):
        # ì°¸ì—¬í•œ í•™ìƒ ID ëª©ë¡ ìƒì„±
        participant_ids = set()
        for msg in recent_messages:
            if msg.get('sender_id') and msg['sender_id'].startswith('2s'):
                participant_ids.add(msg['sender_id'])
        
        participant_list = ", ".join(participant_ids)
        
        chat_text = "\n".join([f"{m.get('name', m['sender_id'])}: {m['message']}" for m in recent_messages])
        system_prompt = await get_system_prompt(self.room_id)

        judgment_instruction = f"""
ì´ ì±„íŒ…ë°©ì€ ìœ„ì™€ ê°™ì€ ëª©ì ì„ ê°€ì§„ ê³µê°„ì…ë‹ˆë‹¤.

GPTëŠ” êµì‚¬ì˜ ë³´ì¡°êµì‚¬ë¡œì„œ, ë‹¤ìŒ ê¸°ì¤€ì— ë”°ë¼ ê°œì… ìƒí™©ì„ íŒë‹¨í•˜ì„¸ìš”:

ìƒí™© 1: í•™ìƒë“¤ì´ ì£¼ì–´ì§„ ì£¼ì œì— ë§ê²Œ ì˜ í† ë¡ í•˜ê³  ìˆë‹¤ë©´ â†’ ê¸ì •ì ì¸ í”¼ë“œë°± (ì‘ë‹µ ìœ í˜•: "positive")
ìƒí™© 2: í•™ìƒë“¤ì´ ì£¼ì–´ì§„ ì£¼ì œì™€ ë§ì§€ ì•Šê²Œ ëŒ€í™”í•˜ê±°ë‚˜ ë°©í–¥ì„±ì´ í•„ìš”í•œ ê²½ìš° â†’ ë°©í–¥ ì œì‹œ í”¼ë“œë°± (ì‘ë‹µ ìœ í˜•: "guidance")
ìƒí™© 3: íŠ¹ì • í•™ìƒì´ ì˜ ì°¸ì—¬í•˜ì§€ ëª»í•˜ê±°ë‚˜ ë°©í–¥ì´ ë‹¤ë¥¸ ë§ì„ í•˜ëŠ” ê²½ìš° â†’ ê°œì¸ í”¼ë“œë°± (ì‘ë‹µ ìœ í˜•: "individual")
ìƒí™© 4: ê°œì…ì´ ë¶ˆí•„ìš”í•œ ê²½ìš° â†’ ê°œì…í•˜ì§€ ì•ŠìŒ (ì‘ë‹µ ìœ í˜•: "none")

í˜„ì¬ ì±„íŒ…ì— ì°¸ì—¬ ì¤‘ì¸ í•™ìƒ ID ëª©ë¡: {participant_list}

ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "intervention_type": "positive" ë˜ëŠ” "guidance" ë˜ëŠ” "individual" ë˜ëŠ” "none",
  "target_student": null ë˜ëŠ” ì‹¤ì œ í•™ìƒ ID (ì˜ˆ: "2s01", "2s02" ë“±, ê°œì¸ í”¼ë“œë°±ì¸ ê²½ìš°ë§Œ í•™ìƒ ID ì§€ì •),
  "reasoning": "íŒë‹¨ ì´ìœ ë¥¼ ê°„ëµíˆ ì„¤ëª…"
}}

âš ï¸ ë§¤ìš° ì¤‘ìš”: "target_student"ëŠ” ë°˜ë“œì‹œ ìœ„ ì°¸ì—¬ì ëª©ë¡ì— ìˆëŠ” í•™ìƒ IDë§Œ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.
âš ï¸ í•™ìƒ ì´ë¦„ì´ë‚˜ ë²ˆí˜¸ê°€ ì•„ë‹Œ ì •í™•í•œ IDë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
âš ï¸ ì˜ëª»ëœ IDë¥¼ ì§€ì •í•˜ë©´ ë©”ì‹œì§€ê°€ ì—‰ëš±í•œ í•™ìƒì—ê²Œ ì „ì†¡ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
âš ï¸ JSON ì™¸ì˜ ì„¤ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""

        full_prompt = f"{system_prompt.strip()}\n\n{judgment_instruction.strip()}"

        messages = [
            {"role": "system", "content": full_prompt},
            {"role": "user", "content": f"ìµœê·¼ ëŒ€í™”:\n{chat_text}"}
        ]

        try:
            response = await client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0
            )
            raw = response.choices[0].message.content.strip()
            print("ğŸ§  GPT íŒë‹¨ ì‘ë‹µ:", raw)
            result = json.loads(raw)
            
            # ì´ì „ í˜•ì‹ê³¼ì˜ í˜¸í™˜ì„± ìœ ì§€
            should_respond = result["intervention_type"] != "none"
            target = result.get("target_student") if result["intervention_type"] == "individual" else None
            
            # âš ï¸ ì•ˆì „ì„± ê²€ì¦: targetì´ ì°¸ì—¬ì ëª©ë¡ì— ìˆëŠ”ì§€ í™•ì¸
            if target and target not in participant_ids:
                print(f"âš ï¸ GPTê°€ ì˜ëª»ëœ í•™ìƒ ID({target})ë¥¼ ì§€ì •í–ˆìŠµë‹ˆë‹¤. ì°¸ì—¬ì ëª©ë¡: {participant_list}")
                # ê°œì¸ í”¼ë“œë°±ì„ ì „ì²´ í”¼ë“œë°±ìœ¼ë¡œ ë³€ê²½
                result["intervention_type"] = "guidance"
                result["target_student"] = None
                result["reasoning"] += " (ê²½ê³ : ëŒ€ìƒ í•™ìƒ IDê°€ ì°¸ì—¬ì ëª©ë¡ì— ì—†ì–´ ì „ì²´ í”¼ë“œë°±ìœ¼ë¡œ ë³€ê²½ë¨)"
                target = None
                print("âš ï¸ ê°œì¸ í”¼ë“œë°±ì´ ì „ì²´ í”¼ë“œë°±ìœ¼ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            return {
                "should_respond": should_respond,
                "target": target,
                "target_student": target,
                "intervention_type": result["intervention_type"],
                "reasoning": result.get("reasoning", "")
            }
        except Exception as e:
            print("âŒ íŒë‹¨ ì˜¤ë¥˜:", e)
            return {"should_respond": False, "intervention_type": "none", "target": None}

    async def generate_feedback(self, recent_messages, intervention_type, target=None):
        system_prompt = await get_system_prompt(self.room_id)
        chat_text = "\n".join([f"{m.get('name', m['sender_id'])}: {m['message']}" for m in recent_messages])
        
        # ì°¸ì—¬ì ëª©ë¡ ìƒì„± (ìœ íš¨í•œ íƒ€ê²Ÿ í™•ì¸ìš©)
        participant_ids = set()
        for msg in recent_messages:
            if msg.get('sender_id') and msg['sender_id'].startswith('2s'):
                participant_ids.add(msg['sender_id'])
        
        feedback_instruction = ""
        
        if intervention_type == "positive":
            feedback_instruction = """
í•™ìƒë“¤ì´ ì£¼ì–´ì§„ ì£¼ì œì— ë§ê²Œ ì˜ í† ë¡ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ê¸ì •ì ì¸ í”¼ë“œë°±ì„ í†µí•´ í•™ìƒë“¤ì˜ ëŒ€í™”ë¥¼ ì¥ë ¤í•´ì£¼ì„¸ìš”.
ëª…í™•í•œ ë¬¸ì¥ìœ¼ë¡œ í•™ìƒë“¤ì˜ ì¢‹ì€ ì ì„ ì¹­ì°¬í•˜ê³  ê³„ì† ëŒ€í™”ë¥¼ ì´ì–´ê°€ë„ë¡ ë™ê¸°ë¶€ì—¬ í•´ì£¼ì„¸ìš”.
"""
            temperature = 0.5
            
        elif intervention_type == "guidance":
            feedback_instruction = """
í•™ìƒë“¤ì´ ì£¼ì–´ì§„ ì£¼ì œì—ì„œ ë²—ì–´ë‚˜ê³  ìˆê±°ë‚˜ ë°©í–¥ì„±ì´ í•„ìš”í•©ë‹ˆë‹¤.
ì£¼ì œë¡œ ë‹¤ì‹œ ì§‘ì¤‘í•  ìˆ˜ ìˆë„ë¡ ì•ˆë‚´í•´ì£¼ì„¸ìš”.
ì¹œì ˆí•˜ê³  ëª…í™•í•œ ë°©í–¥ ì œì‹œì™€ í•¨ê»˜ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì´ë‚˜ í™œë™ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.
500ì ë‚´ì™¸ë¡œ íš¨ê³¼ì ì¸ í”¼ë“œë°±ì„ ì‘ì„±í•˜ì„¸ìš”.
"""
            temperature = 0.7
            
        elif intervention_type == "individual":
            # íƒ€ê²Ÿ í•™ìƒì´ ìœ íš¨í•œì§€ ì¬í™•ì¸
            if not target or target not in participant_ids:
                print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ í•™ìƒ IDë¡œ ê°œì¸ í”¼ë“œë°± ìƒì„± ì‹œë„: {target}")
                # ëŒ€ì•ˆìœ¼ë¡œ ì¼ë°˜ ì•ˆë‚´ í”¼ë“œë°± ì œê³µ
                return "í˜„ì¬ ëŒ€í™”ì— ë„ì›€ì´ í•„ìš”í•´ ë³´ì…ë‹ˆë‹¤. ì£¼ì œì— ë§ê²Œ ì§‘ì¤‘í•´ì„œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤."
                
            try:
                student_name = get_student_name(target)
                if not student_name or student_name == target:
                    # ì´ë¦„ì„ ê°€ì ¸ì˜¤ì§€ ëª»í•œ ê²½ìš° IDë¡œ ëŒ€ì²´
                    student_name = f"í•™ìƒ({target})"
            except Exception as e:
                print(f"âŒ í•™ìƒ ì´ë¦„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
                student_name = f"í•™ìƒ({target})"
                
            feedback_instruction = f"""
íŠ¹ì • í•™ìƒ({student_name}, ID: {target})ì—ê²Œ ê°œì¸ì ì¸ í”¼ë“œë°±ì´ í•„ìš”í•©ë‹ˆë‹¤.
ì´ í•™ìƒì€ ì°¸ì—¬ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ í† ë¡  ë°©í–¥ê³¼ ë‹¤ë¥¸ ëŒ€í™”ë¥¼ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
í•™ìƒì„ ì¡´ì¤‘í•˜ë©´ì„œë„ ëª…í™•í•˜ê²Œ ë„ì›€ì„ ì£¼ëŠ” ê°œì¸ í”¼ë“œë°±ì„ ì‘ì„±í•˜ì„¸ìš”.
ì´ ë©”ì‹œì§€ëŠ” í•´ë‹¹ í•™ìƒì—ê²Œë§Œ ë³´ì´ëŠ” ê·“ì†ë§ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.
500ì ë‚´ì™¸ë¡œ íš¨ê³¼ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
"""
            temperature = 0.7
        
        else:
            # ê°œì…ì´ ì—†ëŠ” ê²½ìš° (ì´ ì½”ë“œëŠ” ì‹¤í–‰ë˜ì§€ ì•Šì•„ì•¼ í•¨)
            return "í”¼ë“œë°±ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

        prompt_messages = [
            {"role": "system", "content": f"{system_prompt}\n\n{feedback_instruction}"},
            {"role": "user", "content": f"ìµœê·¼ ëŒ€í™”:\n{chat_text}"}
        ]

        try:
            response = await client.chat.completions.create(
                model="gpt-4o-mini",
                messages=prompt_messages,
                temperature=temperature
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print("âŒ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜:", e)
            return "ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”."

    async def process_auto_intervention(self, recent_messages, sid_to_user, sio):
        judgment = await self.should_respond(recent_messages)
        should_respond = judgment.get("should_respond", False)
        intervention_type = judgment.get("intervention_type", "none")
        target = judgment.get("target")
        reasoning = judgment.get("reasoning", "")
        
        if not should_respond:
            print("ğŸ¤– GPT íŒë‹¨: ê°œì… ë¶ˆí•„ìš”")
            return
        
        # ì•ˆì „ì„± ê²€ì¦: íƒ€ê²Ÿ í•™ìƒì´ ì§€ì •ë˜ì—ˆëŠ”ë° ì‹¤ì œ ì°¸ì—¬ì ëª©ë¡ì— ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
        if intervention_type == "individual" and target:
            # ì‹¤ì œ ì±„íŒ…ë°© ì°¸ì—¬ì ID ëª©ë¡
            participant_ids = list(sid_to_user.values())
            
            if target not in participant_ids:
                print(f"âš ï¸ ê²½ê³ : íƒ€ê²Ÿ í•™ìƒ ID({target})ê°€ ì°¸ì—¬ì ëª©ë¡ì— ì—†ìŠµë‹ˆë‹¤!")
                print(f"ğŸ’¡ ì°¸ì—¬ì ëª©ë¡: {participant_ids}")
                
                # ì—ëŸ¬ ë¡œê¹… í›„ ê°œì¸ í”¼ë“œë°±ì„ ì „ì²´ í”¼ë“œë°±ìœ¼ë¡œ ë³€ê²½
                intervention_type = "guidance"
                target = None
                reasoning += " (ì£¼ì˜: ê°œì¸ í”¼ë“œë°±ì´ ì „ì²´ í”¼ë“œë°±ìœ¼ë¡œ ë³€ê²½ë¨ - ëŒ€ìƒ í•™ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŒ)"
        
        print(f"ğŸ¤– GPT íŒë‹¨: {intervention_type} ìœ í˜• í”¼ë“œë°± ì œê³µ" + (f" ({target}ì—ê²Œ)" if target else ""))
        
        gpt_text = await self.generate_feedback(recent_messages, intervention_type, target)
        gpt_time = datetime.utcnow().isoformat()

        # ë©”ì‹œì§€ DB ì €ì¥
        saved_message = await save_message_to_db(
            self.room_id, 
            "gpt", 
            gpt_text, 
            "assistant", 
            gpt_time, 
            whisper_to=target if intervention_type == "individual" else None,
            reasoning=reasoning
        )
        
        print(f"âœ… ë©”ì‹œì§€ ì‘ë‹µ: {saved_message}")

        if intervention_type == "individual" and target:
            # ê°œì¸ í”¼ë“œë°± (ê·“ì†ë§)
            message_sent = False
            for sid, uid in sid_to_user.items():
                if uid == target:
                    await sio.emit("receive_message", {
                        "sender_id": "gpt",
                        "message": gpt_text,
                        "role": "assistant",
                        "timestamp": gpt_time,
                        "target": target,
                        "whisper": True,
                        "whisper_to": target,  # ì¼ê´€ì„±ì„ ìœ„í•´ ë‘ í•„ë“œ ëª¨ë‘ ì„¤ì •
                        "reasoning": reasoning
                    }, to=sid)
                    print(f"âœ‰ï¸ ê·“ì†ë§ ì „ì†¡: {target}ì—ê²Œ")
                    message_sent = True
                    break
            
            # ë©”ì‹œì§€ë¥¼ ë³´ë‚´ì§€ ëª»í–ˆë‹¤ë©´ ë¡œê·¸ì— ê¸°ë¡
            if not message_sent:
                print(f"âš ï¸ ê²½ê³ : {target}ì—ê²Œ ê·“ì†ë§ì„ ë³´ë‚´ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í´ë¼ì´ì–¸íŠ¸ê°€ ì—°ê²°ë˜ì–´ ìˆì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            # ì „ì²´ í”¼ë“œë°±
            await sio.emit("receive_message", {
                "sender_id": "gpt",
                "message": gpt_text,
                "role": "assistant",
                "timestamp": gpt_time,
                "feedback_type": intervention_type,
                "reasoning": reasoning
            }, room=self.room_id)
            print(f"ğŸ“¢ ì „ì²´ ë©”ì‹œì§€ ì „ì†¡: {intervention_type} ìœ í˜•")

    async def generate_direct_response(self, recent_messages, student_question, student_id):
        """
        í•™ìƒì´ GPTì—ê²Œ ì§ì ‘ ì§ˆë¬¸í•œ ê²½ìš° ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
        - recent_messages: ìµœê·¼ ëŒ€í™” ê¸°ë¡
        - student_question: í•™ìƒì˜ ì§ˆë¬¸
        - student_id: ì§ˆë¬¸í•œ í•™ìƒì˜ ID
        """
        system_prompt = await get_system_prompt(self.room_id)
        chat_text = "\n".join([f"{m.get('name', m['sender_id'])}: {m['message']}" for m in recent_messages])
        student_name = get_student_name(student_id) if student_id else "í•™ìƒ"
        
        direct_question_instruction = f"""
{student_name}(ID: {student_id})ê°€ ë‹¹ì‹ ì—ê²Œ ì§ì ‘ ì§ˆë¬¸í–ˆìŠµë‹ˆë‹¤.
ì´ ì±„íŒ…ë°©ì€ '{system_prompt}'ë¼ëŠ” ì£¼ì œ/ëª©ì ì„ ê°€ì§„ ê³µê°„ì…ë‹ˆë‹¤.

ì‘ë‹µ ê°€ì´ë“œë¼ì¸:
1. ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
2. ì¤‘ìš”í•œ ì •ë³´ëŠ” í•œ ë¬¸ë‹¨ì— í•˜ë‚˜ì”© ì œì‹œí•˜ì„¸ìš”.
3. ë‚´ìš©ì´ ë§ë‹¤ë©´ 2-3ê°œì˜ í•µì‹¬ ì¹´í…Œê³ ë¦¬ë¡œ ë‚˜ëˆ„ì–´ ì œì‹œí•˜ì„¸ìš”.
4. í•™ìƒ ìˆ˜ì¤€ì— ë§ëŠ” ì–¸ì–´ë¡œ ì„¤ëª…í•˜ë˜, ì „ë¬¸ ìš©ì–´ê°€ í•„ìš”í•  ë•ŒëŠ” ê°„ë‹¨í•œ ì„¤ëª…ì„ ë§ë¶™ì´ì„¸ìš”.
5. ì²« ë¬¸ì¥ì—ì„œ ì§ˆë¬¸ì˜ í•µì‹¬ì— ì§ì ‘ ë‹µí•˜ê³ , ê·¸ ë‹¤ìŒì— ì¶”ê°€ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
6. ë¬¸ì¥ì€ ì§§ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”. í•œ ë¬¸ì¥ì— 2ê°œ ì´ìƒì˜ ì •ë³´ëŠ” ë‹´ì§€ ë§ˆì„¸ìš”.

ì‘ë‹µ í˜•ì‹:
- ì´ ê¸¸ì´: 500ì ë‚´ì™¸ë¡œ ì œí•œí•˜ì„¸ìš”.
- ** ê¸°í˜¸ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
"""

        prompt_messages = [
            {"role": "system", "content": direct_question_instruction},
            {"role": "user", "content": f"ìµœê·¼ ëŒ€í™”:\n{chat_text}\n\n{student_name}ì˜ ì§ˆë¬¸: {student_question}"}
        ]

        try:
            response = await client.chat.completions.create(
                model="gpt-4o-mini",
                messages=prompt_messages,
                temperature=0.5,  # ë” ì¼ê´€ëœ ì‘ë‹µì„ ìœ„í•´ ì˜¨ë„ ë‚®ì¶¤
                max_tokens=600   # ì‘ë‹µ ê¸¸ì´ ì œí•œ
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print("âŒ ì§ì ‘ ì§ˆë¬¸ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜:", e)
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”."

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í‰ê°€ ì „ìš© í•¨ìˆ˜ (GPT í‰ê°€ ìƒì„±) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def evaluate_conversation(rubric_prompt: str, messages: list[dict]) -> str:
    """
    âœ… GPTì—ê²Œ ë£¨ë¸Œë¦­ê³¼ ì±„íŒ… ëŒ€í™”ë¥¼ ì „ë‹¬í•˜ì—¬ í‰ê°€ ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    - rubric_prompt: êµì‚¬ê°€ ì‘ì„±í•œ í‰ê°€ ê¸°ì¤€
    - messages: [{sender_id, message}, ...]
    - return: í‰ê°€ ìš”ì•½ í…ìŠ¤íŠ¸
    """
    try:
        system_prompt = f"""
ë‹¹ì‹ ì€ êµì‚¬ê°€ ì‘ì„±í•œ ë£¨ë¸Œë¦­ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìƒë“¤ì˜ ëŒ€í™”ë¥¼ í‰ê°€í•˜ëŠ” AI í‰ê°€ ë³´ì¡°ìì…ë‹ˆë‹¤.

ğŸ“‹ ë£¨ë¸Œë¦­:
{rubric_prompt}

ì•„ë˜ ëŒ€í™”ë¥¼ ë¶„ì„í•´ êµì‚¬ì—ê²Œ ì œê³µí•  í‰ê°€ í”¼ë“œë°±ì„ ì‘ì„±í•˜ì„¸ìš”.
"""
        chat_log = "\n".join([f"{m['sender_id']}: {m['message']}" for m in messages])

        prompt_messages = [
            {"role": "system", "content": system_prompt.strip()},
            {"role": "user", "content": f"ëŒ€í™”:\n{chat_log}"}
        ]

        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=prompt_messages,
            temperature=0.7,
        )

        return response.choices[0].message.content.strip()

    except Exception as e:
        print("âŒ GPT í‰ê°€ ìƒì„± ì˜¤ë¥˜:", e)
        return "GPT í‰ê°€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."