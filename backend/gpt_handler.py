import os
import json
from datetime import datetime
from openai import AsyncOpenAI
from supabase_client import (
    get_room_history,
    get_system_prompt,
    get_student_name,
    save_message_to_db
)

client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

class GPTInterventionService:
    """
    GPT ê°œì… ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    - 1ë‹¨ê³„: ê°œì… ì—¬ë¶€ íŒë‹¨
    - 2ë‹¨ê³„: ì‘ë‹µ ìƒì„± ë° ì „ì†¡
    """

    def __init__(self, room_id):
        self.room_id = room_id

    async def should_respond(self, recent_messages):
        chat_text = "\n".join([f"{m.get('name', m['sender_id'])}: {m['message']}" for m in recent_messages])
        system_prompt = await get_system_prompt(self.room_id)

        judgment_instruction = """
ì´ ì±„íŒ…ë°©ì€ ìœ„ì™€ ê°™ì€ ëª©ì ì„ ê°€ì§„ ê³µê°„ì…ë‹ˆë‹¤.

GPTëŠ” êµì‚¬ì˜ ë³´ì¡°êµì‚¬ë¡œì„œ, ë‹¤ìŒ ê¸°ì¤€ì— ë”°ë¼ ê°œì… ìƒí™©ì„ íŒë‹¨í•˜ì„¸ìš”:

ìƒí™© 1: í•™ìƒë“¤ì´ ì£¼ì–´ì§„ ì£¼ì œì— ë§ê²Œ ì˜ í† ë¡ í•˜ê³  ìˆë‹¤ë©´ â†’ ê¸ì •ì ì¸ í”¼ë“œë°± (ì‘ë‹µ ìœ í˜•: "positive")
ìƒí™© 2: í•™ìƒë“¤ì´ ì£¼ì–´ì§„ ì£¼ì œì™€ ë§ì§€ ì•Šê²Œ ëŒ€í™”í•˜ê±°ë‚˜ ë°©í–¥ì„±ì´ í•„ìš”í•œ ê²½ìš° â†’ ë°©í–¥ ì œì‹œ í”¼ë“œë°± (ì‘ë‹µ ìœ í˜•: "guidance")
ìƒí™© 3: íŠ¹ì • í•™ìƒì´ ì˜ ì°¸ì—¬í•˜ì§€ ëª»í•˜ê±°ë‚˜ ë°©í–¥ì´ ë‹¤ë¥¸ ë§ì„ í•˜ëŠ” ê²½ìš° â†’ ê°œì¸ í”¼ë“œë°± (ì‘ë‹µ ìœ í˜•: "individual")
ìƒí™© 4: ê°œì…ì´ ë¶ˆí•„ìš”í•œ ê²½ìš° â†’ ê°œì…í•˜ì§€ ì•ŠìŒ (ì‘ë‹µ ìœ í˜•: "none")

ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{
  "intervention_type": "positive" ë˜ëŠ” "guidance" ë˜ëŠ” "individual" ë˜ëŠ” "none",
  "target_student": null ë˜ëŠ” ì‹¤ì œ í•™ìƒ ID (ì˜ˆ: "2s01", "2s02" ë“±, ê°œì¸ í”¼ë“œë°±ì¸ ê²½ìš°ë§Œ í•™ìƒ ID ì§€ì •),
  "reasoning": "íŒë‹¨ ì´ìœ ë¥¼ ê°„ëµíˆ ì„¤ëª…"
  
}

âš ï¸ ì¤‘ìš”: "target_student"ëŠ” ì´ë¦„ì´ ì•„ë‹Œ ë°˜ë“œì‹œ í•™ìƒ IDë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ "í•™ìƒ30"ì´ë‚˜ "30"ì´ ì•„ë‹Œ "2s03"ê³¼ ê°™ì€ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
âš ï¸ JSON ì™¸ì˜ ì„¤ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""

        full_prompt = f"{system_prompt.strip()}\n\n{judgment_instruction.strip()}"

        messages = [
            {"role": "system", "content": full_prompt},
            {"role": "user", "content": f"ìµœê·¼ ëŒ€í™”:\n{chat_text}"}
        ]

        try:
            response = await client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0
            )
            raw = response.choices[0].message.content.strip()
            print("ğŸ§  GPT íŒë‹¨ ì‘ë‹µ:", raw)
            result = json.loads(raw)
            
            # ì´ì „ í˜•ì‹ê³¼ì˜ í˜¸í™˜ì„± ìœ ì§€
            should_respond = result["intervention_type"] != "none"
            target = result.get("target_student") if result["intervention_type"] == "individual" else None
            
            # targetì´ í•™ìƒ ID í˜•ì‹ì´ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
            if target and not (isinstance(target, str) and target.startswith("2s")):
                # ë©”ì‹œì§€ì—ì„œ í•´ë‹¹ ì´ë¦„ì„ ê°€ì§„ í•™ìƒì˜ ID ì°¾ê¸°
                for msg in recent_messages:
                    name = msg.get("name", "")
                    sender_id = msg.get("sender_id", "")
                    if (name == target or name == f"í•™ìƒ{target}") and sender_id.startswith("2s"):
                        target = sender_id
                        print(f"ğŸ”„ íƒ€ê²Ÿ í•™ìƒ ì´ë¦„ì„ IDë¡œ ë³€í™˜: {name} â†’ {target}")
                        break
            
            return {
                "should_respond": should_respond,
                "target": target,
                "target_student": target,
                "intervention_type": result["intervention_type"],
                "reasoning": result.get("reasoning", "")
            }
        except Exception as e:
            print("âŒ íŒë‹¨ ì˜¤ë¥˜:", e)
            return {"should_respond": False, "intervention_type": "none", "target": None}

    async def generate_feedback(self, recent_messages, intervention_type, target=None):
        system_prompt = await get_system_prompt(self.room_id)
        chat_text = "\n".join([f"{m.get('name', m['sender_id'])}: {m['message']}" for m in recent_messages])
        
        feedback_instruction = ""
        
        if intervention_type == "positive":
            feedback_instruction = """
í•™ìƒë“¤ì´ ì£¼ì–´ì§„ ì£¼ì œì— ë§ê²Œ ì˜ í† ë¡ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ê¸ì •ì ì¸ í”¼ë“œë°±ì„ í†µí•´ í•™ìƒë“¤ì˜ ëŒ€í™”ë¥¼ ì¥ë ¤í•´ì£¼ì„¸ìš”.
ì§§ê³  ëª…í™•í•œ ë¬¸ì¥ìœ¼ë¡œ í•™ìƒë“¤ì˜ ì¢‹ì€ ì ì„ ì¹­ì°¬í•˜ê³  ê³„ì† ëŒ€í™”ë¥¼ ì´ì–´ê°€ë„ë¡ ë™ê¸°ë¶€ì—¬ í•´ì£¼ì„¸ìš”.
"""
            temperature = 0.5
            
        elif intervention_type == "guidance":
            feedback_instruction = """
í•™ìƒë“¤ì´ ì£¼ì–´ì§„ ì£¼ì œì—ì„œ ë²—ì–´ë‚˜ê³  ìˆê±°ë‚˜ ë°©í–¥ì„±ì´ í•„ìš”í•©ë‹ˆë‹¤.
ì£¼ì œë¡œ ë‹¤ì‹œ ì§‘ì¤‘í•  ìˆ˜ ìˆë„ë¡ ì•ˆë‚´í•´ì£¼ì„¸ìš”.
ì¹œì ˆí•˜ê³  ëª…í™•í•œ ë°©í–¥ ì œì‹œì™€ í•¨ê»˜ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì´ë‚˜ í™œë™ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.
100ì ë‚´ì™¸ë¡œ ì§§ê³  íš¨ê³¼ì ì¸ í”¼ë“œë°±ì„ ì‘ì„±í•˜ì„¸ìš”.
"""
            temperature = 0.7
            
        elif intervention_type == "individual":
            student_name = get_student_name(target) if target else "í•™ìƒ"
            feedback_instruction = f"""
íŠ¹ì • í•™ìƒ({student_name}, ID: {target})ì—ê²Œ ê°œì¸ì ì¸ í”¼ë“œë°±ì´ í•„ìš”í•©ë‹ˆë‹¤.
ì´ í•™ìƒì€ ì°¸ì—¬ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ í† ë¡  ë°©í–¥ê³¼ ë‹¤ë¥¸ ëŒ€í™”ë¥¼ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
í•™ìƒì„ ì¡´ì¤‘í•˜ë©´ì„œë„ ëª…í™•í•˜ê²Œ ë„ì›€ì„ ì£¼ëŠ” ê°œì¸ í”¼ë“œë°±ì„ ì‘ì„±í•˜ì„¸ìš”.
ì´ ë©”ì‹œì§€ëŠ” í•´ë‹¹ í•™ìƒì—ê²Œë§Œ ë³´ì´ëŠ” ê·“ì†ë§ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.
100ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê³  íš¨ê³¼ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
"""
            temperature = 0.7
        
        else:
            # ê°œì…ì´ ì—†ëŠ” ê²½ìš° (ì´ ì½”ë“œëŠ” ì‹¤í–‰ë˜ì§€ ì•Šì•„ì•¼ í•¨)
            return "í”¼ë“œë°±ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

        prompt_messages = [
            {"role": "system", "content": f"{system_prompt}\n\n{feedback_instruction}"},
            {"role": "user", "content": f"ìµœê·¼ ëŒ€í™”:\n{chat_text}"}
        ]

        try:
            response = await client.chat.completions.create(
                model="gpt-4o-mini",
                messages=prompt_messages,
                temperature=temperature
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print("âŒ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜:", e)
            return "ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”."

    async def process_auto_intervention(self, recent_messages, sid_to_user, sio):
        judgment = await self.should_respond(recent_messages)
        should_respond = judgment.get("should_respond", False)
        intervention_type = judgment.get("intervention_type", "none")
        target = judgment.get("target")
        reasoning = judgment.get("reasoning", "")
        
        if not should_respond:
            print("ğŸ¤– GPT íŒë‹¨: ê°œì… ë¶ˆí•„ìš”")
            return
            
        print(f"ğŸ¤– GPT íŒë‹¨: {intervention_type} ìœ í˜• í”¼ë“œë°± ì œê³µ" + (f" ({target}ì—ê²Œ)" if target else ""))
        
        gpt_text = await self.generate_feedback(recent_messages, intervention_type, target)
        gpt_time = datetime.utcnow().isoformat()

        # ë©”ì‹œì§€ DB ì €ì¥
        await save_message_to_db(
            self.room_id, 
            "gpt", 
            gpt_text, 
            "assistant", 
            gpt_time, 
            whisper_to=target if intervention_type == "individual" else None,
            reasoning=reasoning
        )

        if intervention_type == "individual" and target:
            # ê°œì¸ í”¼ë“œë°± (ê·“ì†ë§)
            for sid, uid in sid_to_user.items():
                if uid == target:
                    await sio.emit("receive_message", {
                        "sender_id": "gpt",
                        "message": gpt_text,
                        "role": "assistant",
                        "timestamp": gpt_time,
                        "target": target,
                        "whisper": True,
                        "reasoning": reasoning
                    }, to=sid)
                    print(f"âœ‰ï¸ ê·“ì†ë§ ì „ì†¡: {target}ì—ê²Œ")
                    return
        else:
            # ì „ì²´ í”¼ë“œë°±
            await sio.emit("receive_message", {
                "sender_id": "gpt",
                "message": gpt_text,
                "role": "assistant",
                "timestamp": gpt_time,
                "feedback_type": intervention_type,
                "reasoning": reasoning
            }, room=self.room_id)
            print(f"ğŸ“¢ ì „ì²´ ë©”ì‹œì§€ ì „ì†¡: {intervention_type} ìœ í˜•")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í‰ê°€ ì „ìš© í•¨ìˆ˜ (GPT í‰ê°€ ìƒì„±) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def evaluate_conversation(rubric_prompt: str, messages: list[dict]) -> str:
    """
    âœ… GPTì—ê²Œ ë£¨ë¸Œë¦­ê³¼ ì±„íŒ… ëŒ€í™”ë¥¼ ì „ë‹¬í•˜ì—¬ í‰ê°€ ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    - rubric_prompt: êµì‚¬ê°€ ì‘ì„±í•œ í‰ê°€ ê¸°ì¤€
    - messages: [{sender_id, message}, ...]
    - return: í‰ê°€ ìš”ì•½ í…ìŠ¤íŠ¸
    """
    try:
        system_prompt = f"""
ë‹¹ì‹ ì€ êµì‚¬ê°€ ì‘ì„±í•œ ë£¨ë¸Œë¦­ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìƒë“¤ì˜ ëŒ€í™”ë¥¼ í‰ê°€í•˜ëŠ” AI í‰ê°€ ë³´ì¡°ìì…ë‹ˆë‹¤.

ğŸ“‹ ë£¨ë¸Œë¦­:
{rubric_prompt}

ì•„ë˜ ëŒ€í™”ë¥¼ ë¶„ì„í•´ êµì‚¬ì—ê²Œ ì œê³µí•  í‰ê°€ í”¼ë“œë°±ì„ ì‘ì„±í•˜ì„¸ìš”.
"""
        chat_log = "\n".join([f"{m['sender_id']}: {m['message']}" for m in messages])

        prompt_messages = [
            {"role": "system", "content": system_prompt.strip()},
            {"role": "user", "content": f"ëŒ€í™”:\n{chat_log}"}
        ]

        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=prompt_messages,
            temperature=0.7,
        )

        return response.choices[0].message.content.strip()

    except Exception as e:
        print("âŒ GPT í‰ê°€ ìƒì„± ì˜¤ë¥˜:", e)
        return "GPT í‰ê°€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."